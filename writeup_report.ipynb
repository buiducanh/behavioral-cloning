{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# **Behavioral Cloning** \n",
    "---\n",
    "\n",
    "**Behavioral Cloning Project**\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "* Use the simulator to collect data of good driving behavior\n",
    "* Build, a convolution neural network in Keras that predicts steering angles from images\n",
    "* Train and validate the model with a training and validation set\n",
    "* Test that the model successfully drives around track one without leaving the road\n",
    "* Summarize the results with a written report\n",
    "\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./model.png \"Model Visualization\"\n",
    "[image2]: ./sample.png \"Normal Image\"\n",
    "[image3]: ./flippedsample.png \"Flipped Image\"\n",
    "\n",
    "## Rubric Points\n",
    "### Here I will consider the [rubric points](https://review.udacity.com/#!/rubrics/432/view) individually and describe how I addressed each point in my implementation.  \n",
    "\n",
    "---\n",
    "### Files Submitted & Code Quality\n",
    "\n",
    "#### 1. Submission includes all required files and can be used to run the simulator in autonomous mode\n",
    "\n",
    "My project includes the following files:\n",
    "* model.py containing the script to create and train the model\n",
    "* drive.py for driving the car in autonomous mode\n",
    "* model.h5 containing a trained convolution neural network \n",
    "* writeup_report.md or writeup_report.pdf summarizing the results\n",
    "\n",
    "#### 2. Submission includes functional code\n",
    "Using the Udacity provided simulator and my drive.py file, the car can be driven autonomously around the track by executing \n",
    "```sh\n",
    "python drive.py model.h5\n",
    "```\n",
    "\n",
    "#### 3. Submission code is usable and readable\n",
    "\n",
    "The model.py file contains the code for training and saving the convolution neural network. The file shows the pipeline I used for training and validating the model, and it contains comments to explain how the code works.\n",
    "\n",
    "### Model Architecture and Training Strategy\n",
    "\n",
    "#### 1. An appropriate model architecture has been employed\n",
    "\n",
    "My model is based on the Nvidia model. It consists two initial layers to crop and normalize the image data. Then, 5 convolutional layers that activate with elu and run through batch normalization. Finally, the model runs through 4 fully connected layers, including the final output layer, with the elu activation and batch normalization after each layer. The code can be found in `model.py` (line 17 - 73).\n",
    "~~~\n",
    "def network():\n",
    "    # Nvidia Model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Cropping2D(cropping=((60,30), (0,0)), input_shape=(160, 160, 3)))\n",
    "\n",
    "    model.add(Lambda(lambda x: (x / 127.5) - 1))\n",
    "\n",
    "    # First Convolutional Layer\n",
    "    model.add(Conv2D(nb_filter = 24, nb_row = 5, nb_col = 5, subsample = (2, 2)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Second Convolutional Layer\n",
    "    model.add(Conv2D(nb_filter = 36, nb_row = 5, nb_col = 5, subsample = (2, 2)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Third Convolutional Layer\n",
    "    model.add(Conv2D(nb_filter = 48, nb_row = 5, nb_col = 5, subsample = (2, 2)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Fourth Convolutional Layer\n",
    "    model.add(Conv2D(nb_filter = 64, nb_row = 3, nb_col = 3, subsample = (1, 1)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Fifth Convolutional Layer\n",
    "    model.add(Conv2D(nb_filter = 64, nb_row = 3, nb_col = 3, subsample = (1, 1)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # First Fully Connected Layer\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Second Fully Connected Layer\n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Third Fully Connected Layer\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Output\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Choose optimizer and loss\n",
    "    model.compile(loss = 'mse', optimizer= 'adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "~~~\n",
    "\n",
    "#### 2. Attempts to reduce overfitting in the model\n",
    "\n",
    "The model uses batch normalization which has a slight regularization effect since it adds noises to the hidden layers. Thus, batch normalization helps us avoid overfitting.\n",
    "\n",
    "#### 3. Model parameter tuning\n",
    "\n",
    "The model used an adam optimizer, so the learning rate was not tuned manually `model.py` (line 71). As I train the network at 2 epochs and then 5 epochs, I found that the loss keeps decreasing. So eventually I increased it to 10 and got the model to drive correctly.\n",
    "\n",
    "#### 4. Appropriate training data\n",
    "\n",
    "Training data was chosen to keep the vehicle driving on the road. I used a combination of center lane driving, recovering from the left and right sides of the road, flipped center image to eliminate left turn bias.\n",
    "\n",
    "For details about how I created the training data, see the next section. \n",
    "\n",
    "### Model Architecture and Training Strategy\n",
    "\n",
    "#### 1. Solution Design Approach\n",
    "\n",
    "The overall strategy for deriving a model architecture was to use the Nvidia model as the baseline, and then I tweaked the parameters of the network like the shape of the layers to work with my data. Specifically, the Nvidia model takes input of shape 66x200x3, but I changed it to 160x160x3.\n",
    "\n",
    "Then I added a Keras cropping layer to focus the model on the road. To combat overfitting and help with convergence, I used batch normalization after each hidden layer. I also chose to use `elu` activation function as it is very easy to use and avoid the problems of `relu`.\n",
    "\n",
    "In order to gauge how well the model was working, I split my image and steering angle data into a training and validation set. The Nvidia tweaks worked well at first when I trained with a small sample of the data (about 300 samples) and 2 epochs. The car was running off track at this point.\n",
    "\n",
    "Then I ran on the full data set at 2 epochs. And the car did really well but still ran off track at the mid way point.\n",
    "\n",
    "I then trained with 5 epochs and 10 epochs. At 5 epochs, the car still ran off the road, but I noticed that all 5 epochs saw the accuracy increasing. Thus, I increased the number of epochs and eventually got the car to drive correctly.\n",
    "\n",
    "#### 2. Final Model Architecture\n",
    "\n",
    "Here is a visualization of the architecture (note: visualizing the architecture is optional according to the project rubric)\n",
    "\n",
    "![alt text][image1]\n",
    "\n",
    "#### 3. Creation of the Training Set & Training Process\n",
    "\n",
    "I used sample data from Udacity only.\n",
    "\n",
    "To augment the data set, I also flipped images and angles in order to eliminate left-turn bias, since the sample data only runs on track 1. For example, here is an image that has then been flipped:\n",
    "\n",
    "![alt text][image2] ![alt text][image3]\n",
    "\n",
    "I also use the left and right camera images and apply a correction factor to help the model recover from the curb.\n",
    "\n",
    "After the collection and augmentation process, I had 32140 number of data points. I then preprocessed this data by halving the width of the images, in order to reduce the input space, note that I also add this resize step to `drive.py` to input correct data into the model.\n",
    "\n",
    "I finally randomly shuffled the data set and put 20% of the data into a validation set. \n",
    "\n",
    "I used this training data for training the model. The validation set helped determine if the model was over or under fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
